{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Imports\n",
    "We are working with PyTorch here, so we have some things that we need to import. Here is what everything does:\n",
    "\n",
    "1. Module: Used for making a PyTorch module, we make a feedforward module here\n",
    "\n",
    "2. Linear: Torch layer that implements a simple weighted forward pass, $y = W * x + b$\n",
    "\n",
    "3. BCEWithLogitsLoss: Implementing a BinaryCrossEntropy loss with an integrated sigmoid function, given by $-\\omega_n \\times [y_n . log(\\sigma(x_n)) + (1- y_n) . log(1 - \\sigma(x_n))]$\n",
    "\n",
    "4. ReLU: An activation function, given my $max(0, x)$\n",
    "\n",
    "5. Sigmoid: An activation function, given by $\\frac{1}{1 - exp(-x)}$\n",
    "\n",
    "6. Optimizer: Adam, alternative will be stochastic gradient descent\n",
    "\n",
    "7. DataUtils: The data loader / utility function, made to load in MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module, Linear, BCEWithLogitsLoss, Sigmoid\n",
    "from torch.optim import Adam\n",
    "from torch import count_nonzero\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "from data import DataUtils\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff12f96d670>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"231.84pt\" version=\"1.1\" viewBox=\"0 0 231.84 231.84\" width=\"231.84pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2021-01-26T04:05:50.548128</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 231.84 \n",
       "L 231.84 231.84 \n",
       "L 231.84 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g clip-path=\"url(#pdec25c1e28)\">\n",
       "    <image height=\"218\" id=\"image5a7341a6ca\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"7.2\" xlink:href=\"data:image/png;base64,\n",
       "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\" y=\"-6.64\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pdec25c1e28\">\n",
       "   <rect height=\"217.44\" width=\"217.44\" x=\"7.2\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 50\n",
    "\n",
    "# load the train and test datasets\n",
    "train, test, _ = DataUtils(batch=1).loadTorchDataset()\n",
    "\n",
    "# make the image from flattened data\n",
    "image = train.dataset[index][0].reshape(28,28)\n",
    "\n",
    "# plot\n",
    "plt.axis('off')\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FeedForward Network\n",
    "We need to make sure that the number of inputs and outputs are correct. We are writing a simple feedforward code.\n",
    "Linear (ReLU) -> Linear (ReLU) -> Linear (ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(Module):\n",
    "    def __init__(self, nodesinp, nodes1, nodes2):\n",
    "        super().__init__()\n",
    "        self.ff1 = Linear(nodesinp, nodes1)\n",
    "        self.ff2 = Linear(nodes1, nodes2)\n",
    "        self.ff3 = Linear(nodes2, 10)\n",
    "        self.sig = Sigmoid()\n",
    "\n",
    "    def forward(self, inp):\n",
    "        layer1 = self.ff1(inp)\n",
    "        layer1 = self.sig(layer1)\n",
    "        layer2 = self.ff2(layer1)\n",
    "        layer2 = self.sig(layer2)\n",
    "        layer3 = self.ff3(layer2)\n",
    "        return layer3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Network Class\n",
    "Writing the network class is pretty simple, we just need to fit in the loss function, optimizer and epochs together, and use what we learnt from the last section as a lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, epochs=10, loss=BCEWithLogitsLoss, opt=Adam):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = 1e-4\n",
    "        self.model = FeedForward(784, 500, 20)\n",
    "        self.trainData, self.testData, self.testLabels = DataUtils(batch=10).loadTorchDataset()\n",
    "        self.optimizer = opt(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.lossfn = loss()\n",
    "        \n",
    "\n",
    "    def train(self):\n",
    "        print(f'\\nNOTE: Training model with {self.epochs} epoch(s)')\n",
    "        model = self.model\n",
    "        model.train()\n",
    "        for epochs in range(1, self.epochs + 1):\n",
    "            for batch_idx, (data, target) in enumerate(self.trainData):\n",
    "                opt = self.optimizer\n",
    "                lossfn = self.lossfn\n",
    "                output = model(data)\n",
    "                opt.zero_grad()\n",
    "                one_hot_target = one_hot(target.type('torch.LongTensor'), num_classes=10)\n",
    "                loss = lossfn(output, one_hot_target.type('torch.FloatTensor'))\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            print(f'(epoch {epochs}): completed with loss {loss.item()}')\n",
    "        print('NOTE: Training complete')\n",
    "\n",
    "    def test(self):\n",
    "        print('\\nNOTE: Testing model')\n",
    "        model = self.model\n",
    "        data, target = self.testData, self.testLabels\n",
    "        prediction = model(data)\n",
    "        _, prediction = torch.max(prediction, dim=1)\n",
    "        accTensor = prediction - target\n",
    "        inaccuracy = (count_nonzero(accTensor) / data.shape[0]) * 100\n",
    "        print(f'NOTE: Accuracy on the testing set is {100 - inaccuracy.item()}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: The model summary is given below:\n",
      "FeedForward(\n",
      "  (ff1): Linear(in_features=784, out_features=500, bias=True)\n",
      "  (ff2): Linear(in_features=500, out_features=20, bias=True)\n",
      "  (ff3): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n",
      "\n",
      "NOTE: Training model with 5 epoch(s)\n",
      "(epoch 1): completed with loss 0.22959226369857788\n",
      "(epoch 2): completed with loss 0.10943304002285004\n",
      "(epoch 3): completed with loss 0.09881990402936935\n",
      "(epoch 4): completed with loss 0.023753397166728973\n",
      "(epoch 5): completed with loss 0.0461372509598732\n",
      "NOTE: Training complete\n",
      "\n",
      "NOTE: Testing model\n",
      "NOTE: Accuracy on the testing set is 95.42000007629395%\n"
     ]
    }
   ],
   "source": [
    "net = Network(epochs=5)\n",
    "print('NOTE: The model summary is given below:')\n",
    "print(net.model)\n",
    "net.train()\n",
    "net.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
